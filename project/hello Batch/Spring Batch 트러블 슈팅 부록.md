
# 🙇‍♂Spring Batch 트러블 슈팅 부록

#프로젝트 #개발 #SPRING #Batch #Partitioning #Chunk

---

# size별 소요시간 데이터

1 .GridSize: 4  ActiveConnections: 9/50 소요시간: 6 minutes 23.55
2 .GridSize: 5  ActiveConnections: 11/50 소요시간: 4 minutes 55.57
3 .GridSize: 6  ActiveConnections: 13/50 소요시간: 4 minutes 47.01
4 .GridSize: 7  ActiveConnections: 15/50 소요시간: 3 minutes 47.76
5 .GridSize: 8  ActiveConnections: 17/50 소요시간: 3 minutes 47.69
6 .GridSize: 9  ActiveConnections: 19/50 소요시간: 3 minutes 59.85
7 .GridSize: 10  ActiveConnections: 21/50 소요시간: 3 minutes 6.98
8 .GridSize: 11  ActiveConnections: 23/50 소요시간: 3 minutes 0.52
9 .GridSize: 12  ActiveConnections: 25/50 소요시간: 3 minutes 5.61

---

# 최종 데이터

## 기존 예치금 차액 로직 ( 기준일 기준 하루 전 모든 입/출금 회원)

12월21일
164컬럼
10분 40.783

12월20일
161컬럼
10분 10.794

12월19일
223컬럼
14분 29.279초

12월18일
181컬럼
11분 09.660초

12월17일
329컬럼
19분 56.948초

-

12월14일
220컬럼
13분 28.209초

12월13일
179컬럼
10분 57.596초

12월12일
236컬럼
14분 30.033초

12월11일
226컬럼
14분 02.939초

## 신규 예치금 차액 로직

12월21일
startDate=2024-12-14 07:30:00:00&endDate=2024-12-21 07:30:00
388컬럼
4분 43.53초

12월20일
startDate=2024-12-13 07:30:00:00&endDate=2024-12-20 07:30:00
388컬럼
4분 44.438초

12월19일
startDate=2024-12-12 07:30:00:00&endDate=2024-12-19 07:30:00
387컬럼
4분 41.215초

12월18일
startDate=2024-12-11 07:30:00:00&endDate=2024-12-18 07:30:00
395컬럼
4분 50.9초

12월17일
startDate=2024-12-10 07:30:00:00&endDate=2024-12-17 07:30:00
407컬럼
4분 55.686초

-

12월14일
startDate=2024-12-07 07:30:00:00&endDate=2024-12-14 07:30:00
376컬럼
4분 35.387초

12월13일
startDate=2024-12-06 07:30:00:00&endDate=2024-12-13 07:30:00
384컬럼
4분 43.642초

12월12일
startDate=2024-12-05 07:30:00:00&endDate=2024-12-12 07:30:00
438컬럼
4분 47.027초

12월11일
startDate=2024-12-04 07:30:00:00&endDate=2024-12-11 07:30:00
437컬럼
4분 54.308초



1. 4일 7:30분-5일 7:30분
2. 5일 7:30분-6일 7:30분
3. 6일 7:30분-7일 7:30분
4. 7일 7:30분-8일 7:30분
5. 8일 7:30분-9일 7:30분
6. 9일 7:30분-10일 7:30분
7. 10일 7:30분-11일 7:30분

![[output (9).png]]
---

dev 배치 IP
## 10.22.164.107:8010

운영 배치 IP
10.22.161.86:8010
---
localhost:8010/run-newMemberBalance?gridSize=6&startDate=2017-11-29 00:00:00&endDate=2017-12-01 23:59:59

localhost:8010/run-memberBalance?startDate=2017-11-29&endDate=2017-12-01


# 최종 테스트 ==( 삭제 )==

##### 
### 기존 Batch

```
### 300테스트 1
## 범위 - 2016-09-28 ~ 2016-12-13
startDate=2016-09-28&endDate=2016-12-13
## 컬럼 개수 - 289개
6분 22초


### 300테스트 2
## 범위 - 2016-12-13 ~ 2017-01-16
startDate=2016-12-13&endDate=2017-01-16
## 컬럼 개수 - 280개
5분 57초


### 300테스트 3
## 범위 - 2017-01-11 ~ 2017-02-13
startDate=2017-01-11&endDate=2017-02-13
## 컬럼 개수 - 286개
6분 23초


### 300테스트 4
## 범위 - 2017-05-17 ~ 2017-06-01
startDate=2017-05-17&endDate=2017-06-01
## 컬럼 개수 - 274개
5분 54초


### 300테스트 5
## 범위 - 2017-11-07 ~ 2017-12-01
startDate=2017-11-07&endDate=2017-12-01
## 컬럼 개수 - 292개
6분 32초

--------------------------------------------------

### 1100테스트 1-1
## 범위 - 2018-02-11 ~ 2018-05-06
startDate=2018-02-11&endDate=2018-05-06
## 컬럼 개수 - 1094개(예상)
22분 45초

### 1100테스트 1-2
## 범위 - 2018-02-11 ~ 2018-05-06
startDate=2018-02-11&endDate=2018-05-06
## 컬럼 개수 - 1094개(예상)
22분 34초
```
### 기존 로직 
#### 1컬럼당 평균 소요시간 : 1.3 s

# parallelStream vs CompletableFuture 서비스의 api호출 로직을 더 효율적으로 관리할 수는 없을까?

- 현재 예치금 차액 배치의 서비스로직은, 각 파티션에서 실행되며,
- 이렇게 실행된 코드는 parallelStream을 사용하여 내부적인 병렬처리를 진행한다.
- 해당 로직의 특징은 cpu에 부하를 주는 계산식이 아닌, 단순 I/O (api호출 대기)의 소요시간이 크다.

#### **작업 시나리오**

- API 호출 작업 10,000건 처리
- 각 호출 응답 시간 200ms

#### **`parallelStream`**의 성능:

- 기본 스레드 풀 크기: `CPU 코어 수 - 1` (예: 7개의 코어)
- 처리 시간 ≈ 작업 개수/스레드 수×응답 시간\text{작업 개수} / \text{스레드 수} \times \text{응답 시간}작업 개수/스레드 수×응답 시간
- ≈10,000/7×200ms\approx 10,000 / 7 \times 200ms≈10,000/7×200ms
- ≈286초\approx 286초≈286초

#### ==CompletableFuture== + FixedThreadPool(100)**의 성능:

- 스레드 풀 크기: 100
- 처리 시간 ≈ 작업 개수/스레드 수×응답 시간\text{작업 개수} / \text{스레드 수} \times \text{응답 시간}작업 개수/스레드 수×응답 시간
- ≈10,000/100×200ms\approx 10,000 / 100 \times 200ms≈10,000/100×200ms
- ≈20초\approx 20초≈20초
#### **a. 작업의 성격**

- **CPU 바운드 작업**:
    
    - CPU를 많이 사용하는 작업(예: 복잡한 계산)이면, 코어 수 이상의 스레드를 실행할 경우 컨텍스트 스위칭(스레드 간 전환) 비용이 증가해 성능이 오히려 떨어질 수 있습니다.
    - 예: 7개의 코어로 100개의 CPU 작업 스레드를 처리하려 하면 병목이 발생.
- **I/O 바운드 작업**(API 호출 포함):
    
    - 네트워크 I/O 작업은 대기 시간이 길고, 대기 중에는 CPU를 거의 사용하지 않습니다.
    - 이 경우 **스레드 수 > 코어 수**가 유리하며, 100개의 스레드를 실행해도 대부분의 스레드는 대기 상태에 있으므로 CPU 사용량이 낮습니다.


---
### 2차 검증로직 삭제 전
## 기존로직
69961 ms
70048 ms
70396 ms

---
### 2차 검증로직 삭제 후
## 기존 로직
55180 ms
55036 ms
55285 ms
55442 ms
## (계산로직 + API호출 로직) - 스레드 고정(20)
71139 ms
72220 ms
## (API호출 로직만 스레드 고정(20)
64473 ms
65609 ms

- 미리 파티션 되어있는 데이터의 특성상 한번에 처리되는 양이 많지 않다.
- 또한, stream().parallel()은 forkJoinPool에서 효율적으로 관리되며,
- 데이터의 동기화 병목을 줄이고, 컨텍스트 전환 횟수를 줄여 더 효율적인 것으로 보임.
- 사실 잘 모르겠음

#### 결과
- ==stream().parallel()== 기능이 효율적이다.

---

## QuerydslPagingItemReader를 적용함으로 인하여, 일정한 데이터의 크기를 자동으로 페이징 하기 때문에(Reader는 각 Partition별 1번 작동) 스케줄링이 동작할 수 없다.
### 그럼에도 속도가 더 개선된 이유를 분석해보면 좋을것으로 보인다.
- 아마도 Where절이 추가되면서 reader의 속도가 크게 올라갓으며, 1번의 호출만을 하기 때문에 더 개선되었을것이다.

#### 292Column

##### 기존 :
chunk-size:20
55969 ms

##### 변경후 : 
chunk-size:20
54679 ms
54416 ms

---

### 2차 검증 삭제시 최종 차액 인원이 다른 이유
==기존== : reader에서 넘어온녀석들의(옛날기준 날짜범위 내의 가장최신Point)차액 -> 차액이있는녀석들의 (모든날짜 범위내의 최신 Point)의 차액
==현재== : reader에서 가져온녀석들의(모든날짜범위내의 최신 Point)의 차액

### 현재:281 / 기존:141
#### 현재차액에 기존차액이 모두 포함되어있음

=> 옛날기준 날짜범위 내의 가장최신포인트와 실시간 포인트는 다를 경우가 많음. 거기 내에

전날의 최신포인트 vs 현재 최신포인트(신한) -> 여기엔 안걸리지만
현재 최신포인트 vs 현재 최신포인트(신한) -> 여기에는 걸리면 

## 결론 : 예전 차액자 기준으로 오늘날의 차액은 한 번 더 구하는 코드는 옳지 않다.
## 2차 검증 로직을 삭제한 코드가 더 바람직해 보인다.

---

# 회의 안건
## 1. 스레드 풀 개수 정의 어떻게 할것인가?
- 로컬을 기준으로 잡아도, 운영 서버에서 어떠한 스레드 셋팅이 효과적일지 판단하기 힘듬.
- 어떠한 방법을 사용해야 실제 운영 서버 반영 전, 테스트를 할 수 있을지?

## 2. fail list 2차검증 로직 꼭 필요한가?
- 1차에서는 어제 범위 Point (서브쿼리도 메인 쿼리에서 `.where()`에 의해 이미 **어제의 데이터**로 필터링된 상태에서 작동)
- 2차에서는 모든데이터 범위의 최신 Point 
- 배치를 돌리는 현재날짜 0시 ~ 7시 사이에 입출금건이 있는 고객의 경우 1차에서 항상 걸릴 수 밖에 없음Point 
- 1차에서 모두 검증하는 방법은 어떨지?